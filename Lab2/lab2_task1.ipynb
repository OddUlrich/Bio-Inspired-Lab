{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP4660/8420 Lab 2.1 - Using PyTorch for Binary Classification\n",
    "\n",
    "In this lab, you will build your own neural network to perform a basic classification task using PyTorch.\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "Build a neural network for a classification task. The dataset you are using is the Glass Identification data set located at http://archive.ics.uci.edu/ml/datasets/Glass+Identification\n",
    "\n",
    "Have a look!\n",
    "\n",
    "_**Q1. How many instances are in this data set?**_\n",
    "\n",
    "_**Q2. How many attributes (features) are there?**_\n",
    "\n",
    "_**Q3. What was this data set originally used for?**_\n",
    "\n",
    "_**Q4. What is the output attribute? How many output values are there?**_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answers:\n",
    "    Q1: 214.\n",
    "    Q2: 10.\n",
    "    Q3: Criminological investigation.\n",
    "    Q4: Type of glass; 6.\n",
    "    -- 1 building_windows_float_processed \n",
    "    -- 2 building_windows_non_float_processed \n",
    "    -- 3 vehicle_windows_float_processed \n",
    "    -- 4 vehicle_windows_non_float_processed (none in this database) \n",
    "    -- 5 containers \n",
    "    -- 6 tableware \n",
    "    -- 7 headlamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data set “glass.data” and save it as a CSV file, i.e. “glass.csv”.\n",
    "\n",
    "We will begin by simplifying the dataset so that it is only two classes. Make a copy of the original file and name it “glass_binary.csv”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task:\n",
    "**Implement a neural network that classifies the data set based on whether the type of glass is a Window glass or a Non-window glass.** The inputs for the neural network will be the refractive index and measurements for sodium, magnesium, aluminium, silicon, potassium, calcium, barium and iron.\n",
    "\n",
    "Hint: Please refer to Task2 in Lab 1 or Introduction to PyTorch Basics if you don’t know how to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and setup training dataset:\n",
    "**Q5 the second line below removes all the data in the column labelled “Id number”. Why do you think we should not use this data to build a model?**\n",
    "\n",
    "**What does the 4th line below do and why?** Hint: it sets all the values in the final column to either 0 or 1."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answers:\n",
    "    Q5: The Id number is used as the index of each data. it's not a attribute of the data itself. So we should not use it as a feature to build a model.\n",
    "    data.shape[1] is the number of columns for the dataset. Using it as a index is to choose the classes (or categories) of each data. When the value is less than 5, that means it belongs to a Window glass so we label it as '1' and the others, which are Non-window glass, are labelled as '0'. These labels are used as the output label of the classification.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "data = pd.read_csv('dataset/glass/glass.csv',  header=None)\n",
    "\n",
    "# drop first column\n",
    "data.drop(data.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# try shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data[data.shape[1]] = (data[data.shape[1]] < 5).astype(int)\n",
    "\n",
    "# randomly split data into training set (80%) and testing set (20%)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train_data = data[msk]\n",
    "test_data = data[~msk]\n",
    "\n",
    "n_features = train_data.shape[1] - 1\n",
    "\n",
    "# split training data into input and target\n",
    "# the first 9 columns are features, the last one is target\n",
    "train_input = train_data.iloc[:, :n_features]\n",
    "train_target = train_data.iloc[:, n_features]\n",
    "\n",
    "# split training data into input and target\n",
    "# the first 9 columns are features, the last one is target\n",
    "test_input = test_data.iloc[:, :n_features]\n",
    "test_target = test_data.iloc[:, n_features]\n",
    "\n",
    "# create Tensors to hold inputs and outputs, and wrap them in Variables,\n",
    "# as Torch only trains neural network on Variables\n",
    "X = Variable(torch.Tensor(train_input.values).float())\n",
    "Y = Variable(torch.Tensor(train_target.values).long())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO define the number of inputs, classes, training epochs, and learning rate\n",
    "input_neurons = n_features\n",
    "hidden_neurons = 5\n",
    "output_neurons = 2\n",
    "num_epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "#TODO define a customised neural network structure\n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, n_input, n_output):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.out = torch.nn.Linear(n_input, n_output)\n",
    "        \n",
    "#     def forward(self, X):\n",
    "#         y_pred = self.out(X)\n",
    "#         return y_pred\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_input, n_hidden)\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        h_input = self.hidden(X)\n",
    "        h_output = torch.nn.Sigmoid(h_input)\n",
    "        y_pred = self.out(h_output)\n",
    "        return y_pred\n",
    "        \n",
    "#TODO define a neural network using the customised structure \n",
    "# net = Net(input_neurons, output_neurons)\n",
    "net = TwoLayerNet(input_neurons, hidden_neurons, output_neurons)\n",
    "\n",
    "#TODO define loss function (https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#TODO define optimiser (https://pytorch.org/docs/stable/optim.html)\n",
    "optimiser = torch.optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train and test the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2473ea7c42d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Perform forward pass: compute predicted y by passing x to the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e84efb332818>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mh_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mh_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "train_input = train_data.iloc[:, :n_features]\n",
    "train_target = train_data.iloc[:, n_features]\n",
    "# store all losses for visualisation\n",
    "all_losses = []\n",
    "\n",
    "# train a neural network\n",
    "for epoch in range(num_epochs):\n",
    "    # Perform forward pass: compute predicted y by passing x to the model.\n",
    "    Y_pred = net(X)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_func(Y_pred, Y)\n",
    "    all_losses.append(loss.item())\n",
    "\n",
    "    # print progress\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        # convert three-column predicted Y values to one column for comparison\n",
    "        _, predicted = torch.max(Y_pred, 1)\n",
    "\n",
    "        # calculate and print accuracy\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == Y.data.numpy()\n",
    "\n",
    "        print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "              % (epoch + 1, num_epochs, loss.item(), 100 * sum(correct)/total))\n",
    "\n",
    "    # Clear the gradients before running the backward pass.\n",
    "    net.zero_grad()\n",
    "\n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimiser makes an update to its\n",
    "    # parameters\n",
    "    optimiser.step()\n",
    "\n",
    "# Optional: plotting historical loss from ``all_losses`` during network learning\n",
    "# Please uncomment me from next line to ``plt.show()`` if you want to plot loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluating the Results\n",
    "\n",
    "To see how well the network performs on different categories, we will\n",
    "create a confusion matrix, indicating for every glass (rows)\n",
    "which class the network guesses (columns).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "confusion = torch.zeros(output_neurons, output_neurons)\n",
    "\n",
    "Y_pred = net(X)\n",
    "\n",
    "_, predicted = torch.max(Y_pred, 1)\n",
    "\n",
    "for i in range(train_data.shape[0]):\n",
    "    actual_class = Y.data[i]\n",
    "    predicted_class = predicted.data[i]\n",
    "\n",
    "    confusion[actual_class][predicted_class] += 1\n",
    "\n",
    "print('')\n",
    "print('Confusion matrix for training:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 3: Test the neural network\n",
    "\n",
    "Pass testing data to the built neural network and get its performance\n",
    "\"\"\"\n",
    "\n",
    "# create Tensors to hold inputs and outputs, and wrap them in Variables,\n",
    "# as Torch only trains neural network on Variables\n",
    "X_test = Variable(torch.Tensor(test_input.values).float())\n",
    "Y_test = Variable(torch.Tensor(test_target.values).long())\n",
    "optimiser\n",
    "# test the neural network using testing data\n",
    "# It is actually performing a forward pass computation of predicted y\n",
    "# by passing x to the model.\n",
    "# Here, Y_pred_test contains three columns, where the index of the\n",
    "# max column indicates the class of the instance\n",
    "Y_pred_test = net(X_test)\n",
    "\n",
    "# get prediction\n",
    "# convert three-column predicted Y values to one column for comparison\n",
    "_, predicted_test = torch.max(Y_pred_test, 1)\n",
    "\n",
    "# calculate accuracy\n",
    "total_test = predicted_test.size(0)\n",
    "correct_test = sum(predicted_test.data.numpy() == Y_test.data.numpy())\n",
    "\n",
    "print('Testing Accuracy: %.2f %%' % (100 * correct_test / total_test))\n",
    "\n",
    "\"\"\"\n",
    "Evaluating the Results\n",
    "\n",
    "To see how well the network performs on different categories, we will\n",
    "create a confusion matrix, indicating for every iris flower (rows)\n",
    "which class the network guesses (columns).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "confusion_test = torch.zeros(output_neurons, output_neurons)\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    actual_class = Y_test.data[i]\n",
    "    predicted_class = predicted_test.data[i]\n",
    "\n",
    "    confusion_test[actual_class][predicted_class] += 1\n",
    "\n",
    "print('')\n",
    "print('Confusion matrix for testing:')\n",
    "print(confusion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Steps:**\n",
    "1. We encourage you to experiment with different ways of accomplishing the task.\n",
    "2. Explore the normalisation and pre-processing techniques discussed in the lectures and investigate its impact on the performance of the classification.\n",
    "3. Investigate the performance of the neural network classification by changing the various characteristics of the neural network such as:\n",
    "    * Number of neurons in each layer\n",
    "    * Number of layers\n",
    "    * Number of epochs\n",
    "    * Learning rate\n",
    "\n",
    "**Task 2: An advanced classification task in PyTorch**\n",
    "Now we will work with a more complicated classification task, the original glass data set. Load the unmodified data set “glass.csv” into PyTorch and perform the same classification task as above.\n",
    "\n",
    "**Q8. How many classes are you predicting now?**\n",
    "\n",
    "**Q9. How will you represent these classes and how will you calculate the error of classification?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
